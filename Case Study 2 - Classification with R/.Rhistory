evaluate_Weka_classifier(AdaBoostedANNepochs250, newdata = holdout, class = TRUE,
seed = 4747, numFolds = 10)
library(dplyr)
library(RWeka)
library(ggplot2)
library(ROSE)
library(GGally)
origtrain <- read.csv("ChurnTrain.csv")
origtest <- read.csv("ChurnTest.csv")
origtrain$Area.Code <- as.factor(origtrain$Area.Code)
origtest$Area.Code <- as.factor(origtest$Area.Code)
columnstodrop1 <- c("Account.Length","Day.Calls","Eve.Calls","Night.Mins","Night.Calls","Night.Charge")
train1 <- origtrain[ , !(names(origtrain) %in% columnstodrop1)]
test1 <- origtest[ , !(names(origtest) %in% columnstodrop1)]
train2 <- subset(train1, select = -c(Area.Code))
test2 <- subset(test1, select = -c(Area.Code))
dropminutes <- c("Day.Mins","Eve.Mins","Intl.Mins")
train3 <- train2[ , !(names(train2) %in% dropminutes)]
test3 <- test2[ , !(names(test2) %in% dropminutes)]
continuousvars <- c("Day.Charge", "Eve.Charge","Intl.Charge")
stdtrain <- train3 %>% mutate_each_(funs(scale(.) %>% as.vector),
vars = continuousvars)
stdtest <- test3 %>% mutate_each_(funs(scale(.) %>% as.vector),
vars = continuousvars)
set.seed(4747)
rm(list = c("columnstodrop1","continuousvars","dropminutes","InfoGain2","InfoGain3","origtest","origtrain",
"test1","test2","test3","train1","train2","train3"))
trainsize <- floor((nrow(stdtest)/(nrow(stdtrain)+nrow(stdtest)) * nrow(stdtrain)))
subtestrows <- sample(seq_len(nrow(stdtrain)), size = trainsize)
subtraining <- stdtrain[-subtestrows, ]
holdout <- stdtrain[subtestrows, ]
subtrainingOV <-  ovun.sample(Churn. ~ ., data = subtraining, method = "over")$data
AdaBoostedANNepochs250 <- AdaBoostM1(Churn. ~ ., data = subtrainingOV,
control = Weka_control(W=list(MLP, L = 0.15, N = 250)))
MLP <- make_Weka_classifier("weka/classifiers/functions/MultilayerPerceptron")
summary(AdaBoostedANNepochs250, newdata = holdout, class = TRUE)  # Recall = 0.874; Accuracy = 89.6226%
AdaBoostedANNepochs250 <- AdaBoostM1(Churn. ~ ., data = subtrainingOV,
control = Weka_control(W=list(MLP, L = 0.15, N = 250)))
evaluate_Weka_classifier(AdaBoostedANNepochs250, newdata = holdout, class = TRUE,
seed = 4747, numFolds = 10)
finaltrain <-  ovun.sample(Churn. ~ ., data = stdtrain, method = "over")$data
FinalModel <- AdaBoostM1(Churn. ~ ., data = finaltrain,
control = Weka_control(W=list(MLP, L = 0.15, N = 250)))
evaluate_Weka_classifier(FinalModel, class = TRUE, seed = 4747, numFolds = 10)
roc.curve(finaltrain$Churn., predict(FinalModel))
FinalPredictions <- predict(FinalModel, newdata = stdtest)
?write.csv
write.csv(FinalPredictions)
summary(FinalPredictions)
87/(413+87)
summary(stdtrain$Churn.)
410/(2423+410)
write.xlsx(FinalPredictions, "IE 198 Case 2 - Huang.xlsx")
library(xlsx)
write.xlsx(FinalPredictions, "IE 198 Case 2 - Huang.xlsx")
write.csv(FinalPredictions, "IE 198 Case 2 - Huang.csv")
lol <- c(1,2,3,4,5)
rm(lol)
FinalModel <- AdaBoostM1(Churn. ~ ., data = stdtrain,
control = Weka_control(W=list(MLP, L = 0.15, N = 250)))
evaluate_Weka_classifier(FinalModel, class = TRUE, seed = 4747, numFolds = 10)
roc.curve(finaltrain$Churn., predict(FinalModel))
roc.curve(stdtrain$Churn., predict(FinalModel))
roc.curve(finaltrain$Churn., predict(FinalModel))
FinalModel <- AdaBoostM1(Churn. ~ ., data = finaltrain,
control = Weka_control(W=list(MLP, L = 0.15, N = 250)))
evaluate_Weka_classifier(FinalModel, class = TRUE, seed = 4747, numFolds = 10)
roc.curve(finaltrain$Churn., predict(FinalModel))
View(stdtrain)
View(stdtrain)
View(stdtrain)
View(stdtest)
View(stdtest)
